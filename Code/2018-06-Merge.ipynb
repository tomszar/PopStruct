{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging genotypes\n",
    "\n",
    "In this script we will take the harmonized genotypes and merge them.\n",
    "We will remove possible duplicated IIDs, and control plates from the Axiom Array (possible to distinguish them because they don't have sex information).\n",
    "Because [fineStructure](https://people.maths.bris.ac.uk/~madjl/finestructure/) requires a lot of computational resources, we will split our data in two, one retaining most of our samples, and a second one only incorporating samples that we have phenotype data (facial morphology), with the _pheno suffix.\n",
    "The files that have phenotypes (from 2016 batch) are:\n",
    "\n",
    "- ADAPT\n",
    "- SA\n",
    "- UIUC2013\n",
    "- UIUC2014\n",
    "- GHPAFF_Euro\n",
    "- Axiom Array\n",
    "\n",
    "Note that UIUC2014 only contain duplicates from the ADAPT file, so we will remove it from further analysis.\n",
    "Therefore, we will have a \"dense\" (500k) genotype file including only samples with phenotypes:\n",
    "\n",
    "- ADAPT\n",
    "- SA\n",
    "- UIUC2013\n",
    "\n",
    "And a \"sparse\" (30k) genotype file, with most of our samples. Those will be the ones added to the dense file, plus:\n",
    "\n",
    "- Dense\n",
    "    - TD2015\n",
    "    - TD2016\n",
    "    - PSU_FEMMES\n",
    "- Medium:\n",
    "    - GHPAFF_Euro\n",
    "    - GHPAFF_CV\n",
    "- Sparse:\n",
    "    - Axiom Array\n",
    "    - UC_FEMMES (Note that adding UC_FEMMES, the number of SNPs decreases from ~30k to ~10k)\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Let's import modules and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths\n",
    "projpath  = os.path.realpath(\"..\")\n",
    "pathgenos = os.path.join(projpath, \"DataBases\", \"Genotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging each file\n",
    "\n",
    "Let's first merge the different files divided by chromosomes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering every directory in harmonize folder\n",
    "filenames = os.listdir(os.path.join(pathgenos, \"03_Harmonized\"))\n",
    "\n",
    "for filename in filenames: # loop through all the files and folders\n",
    "    if os.path.isdir(os.path.join(pathgenos, \"03_Harmonized\", filename)):\n",
    "        os.chdir(os.path.join(pathgenos, \"03_Harmonized\", filename))\n",
    "        #Opening new file and pasting the file names to use for merging\n",
    "        f = open(filename + \".txt\", \"w+\")\n",
    "        for file in glob.glob(\"*_harmonized.bed\"):\n",
    "            f.write(file.split(\".\")[0] + \"\\n\")\n",
    "        f.close()\n",
    "        #Merge using the file just created. Remove no-sex in CHP (those are plate controls)\n",
    "        if filename.startswith(\"CHP\"):\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "            subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\"), \n",
    "                            \"--remove\", os.path.join(pathgenos, \"03_Harmonized\", \"CHP_1022ppl_114K_hg19_ATGC_geno01_mind01_all_harmonized.nosex\"), \n",
    "                            \"--make-bed\", \"--out\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "        else:\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting IIDs with phenos\n",
    "\n",
    "Now we will extract only the subset of samples with phenotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsphenos = pd.read_csv(\"../IDsRemap2016.txt\", header = None)\n",
    "for file in glob.glob(\"03_Harmonized/*harmonized.bed\"):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #First create a file with merge between phenos and fam file\n",
    "    fam  = pd.read_csv(filename + \".fam\", header = None, sep = \" \").iloc[:,[0,1]]\n",
    "    keep = pd.merge(fam.astype({1:\"str\"}), idsphenos.drop_duplicates(subset = 0), how='inner', left_on = 1, right_on = 0).iloc[:,[0,1]]\n",
    "    keepfilename = filename.split(\"/\")[0] + \"/Phenos/KEEP_\" + filename.split(\"/\")[1]\n",
    "    plinkoutfilename = filename.split(\"/\")[0] + \"/Phenos/\" + filename.split(\"/\")[1] + \"_phenos\"\n",
    "    keep.to_csv(keepfilename, header = None, index = False, sep = \" \")\n",
    "    subprocess.run([\"plink\", \"--bfile\", filename, \"--keep\", keepfilename, \"--make-bed\", \"--out\",  plinkoutfilename])\n",
    "    #count = count +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and cleaning all files\n",
    "\n",
    "Now we will merge all files into a single dataset, following the instructions stated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(os.path.join(pathgenos, \"03_Harmonized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating merging files\n",
    "#Skip this if already done\n",
    "#Remember to delete UIUC 2014 from the list\n",
    "f = open(\"30k_mergefile.txt\", \"w+\")\n",
    "for file in glob.glob(\"*harmonized.bed\"):\n",
    "    f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_2596pp_geno01_mind01', '--filter-founders', '--make-bed', '--out', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_2515pp_geno01_mind01_founders'], returncode=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 500k files in Phenos folder\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"500k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp_geno01_mind01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2596pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2515pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5186pp_geno01_mind01', '--filter-founders', '--make-bed', '--out', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5069pp_geno01_mind01_founders'], returncode=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 30k files\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"30k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5543pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5543pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5543pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5543pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5186pp_geno01_mind01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5186pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5069pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some intermediary files in 04_Merge folder\n",
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*pp.*\"):\n",
    "    os.remove(file)\n",
    "for file in glob.glob(\"*geno01.*\"):\n",
    "    os.remove(file)\n",
    "for file in glob.glob(\"*mind01.*\"):\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many SNPs and samples per file there are.\n",
    "There are no duplicated IIDs left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file: Merge_30k_5069pp_geno01_mind01_founders\n",
      "29636 variants loaded from .bim file.\n",
      "5186 people (1512 males, 2977 females, 697 ambiguous) loaded from .fam.\n",
      "117 people removed due to founder status (--filter-founders).\n",
      "29636 variants and 5069 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: Merge_500k_2515pp_geno01_mind01_founders\n",
      "511262 variants loaded from .bim file.\n",
      "2596 people (954 males, 1642 females) loaded from .fam.\n",
      "81 people removed due to founder status (--filter-founders).\n",
      "511262 variants and 2515 people pass filters and QC.\n",
      "Finished file... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*.log\"):\n",
    "    with open(file) as myfile:\n",
    "        print(\"In file: \" + file.split(\".\")[0])\n",
    "        for num, line in enumerate(myfile, 1):\n",
    "            if \"people\" in line or \"variants\" in line:\n",
    "                print(line, end='')\n",
    "        print(\"Finished file... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by chromosome\n",
    "\n",
    "Now we will split the three files by chromosome to use it as input files for phasing.\n",
    "Also, for each split, we will remove genos and samples with high missing call rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*_founders.bed\"):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #Split by chromosome\n",
    "    for i in range(1,23):\n",
    "        subprocess.run([\"plink\", \"--bfile\", filename, \"--chr\", str(i), \"--geno\", \"--mind\", \"--make-bed\", \"--out\", \"Split/\" + filename + \"_chr_\" + str(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
