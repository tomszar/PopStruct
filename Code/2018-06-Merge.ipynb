{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging genotypes\n",
    "\n",
    "In this script we will take the harmonized genotypes and merge them.\n",
    "We will remove possible duplicated IIDs, and control plates from the Axiom Array (possible to distinguish them because they don't have sex information).\n",
    "Because [fineStructure](https://people.maths.bris.ac.uk/~madjl/finestructure/) requires a lot of computational resources, we will split our data in two, one retaining most of our samples, and a second one only incorporating samples that we have phenotype data (facial morphology), with the _pheno suffix.\n",
    "The files that have phenotypes (from 2016 batch) are:\n",
    "\n",
    "- ADAPT\n",
    "- SA\n",
    "- UIUC2013\n",
    "- UIUC2014\n",
    "- GHPAFF_Euro\n",
    "- Axiom Array\n",
    "\n",
    "Note that UIUC2014 only contain duplicates from the ADAPT file, so we will remove it from further analysis.\n",
    "Therefore, we will have a \"dense\" (500k) genotype file including only samples with phenotypes:\n",
    "\n",
    "- ADAPT\n",
    "- SA\n",
    "- UIUC2013\n",
    "\n",
    "And a \"sparse\" (30k) genotype file, with most of our samples. Those will be the ones added to the dense file, plus:\n",
    "\n",
    "- Dense\n",
    "    - TD2015\n",
    "    - TD2016\n",
    "    - PSU_FEMMES\n",
    "- Medium:\n",
    "    - GHPAFF_Euro\n",
    "    - GHPAFF_CV\n",
    "- Sparse:\n",
    "    - Axiom Array\n",
    "    - UC_FEMMES (Note that adding UC_FEMMES, the number of SNPs decreases from ~30k to ~10k)\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Let's import modules and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths\n",
    "projpath  = os.path.realpath(\"..\")\n",
    "pathgenos = os.path.join(projpath, \"DataBases\", \"Genotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging each file\n",
    "\n",
    "Let's first merge the different files divided by chromosomes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering every directory in harmonize folder\n",
    "filenames = os.listdir(os.path.join(pathgenos, \"03_Harmonized\"))\n",
    "\n",
    "for filename in filenames: # loop through all the files and folders\n",
    "    if os.path.isdir(os.path.join(pathgenos, \"03_Harmonized\", filename)):\n",
    "        os.chdir(os.path.join(pathgenos, \"03_Harmonized\", filename))\n",
    "        #Opening new file and pasting the file names to use for merging\n",
    "        f = open(filename + \".txt\", \"w+\")\n",
    "        for file in glob.glob(\"*_harmonized.bed\"):\n",
    "            f.write(file.split(\".\")[0] + \"\\n\")\n",
    "        f.close()\n",
    "        #Merge using the file just created. Remove no-sex in CHP (those are plate controls)\n",
    "        if filename.startswith(\"CHP\"):\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "            subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\"), \n",
    "                            \"--remove\", os.path.join(pathgenos, \"03_Harmonized\", \"CHP_1022ppl_114K_hg19_ATGC_geno01_maf_hwe_mind01_all_harmonized.nosex\"), \n",
    "                            \"--make-bed\", \"--out\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "        else:\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting IIDs with phenos\n",
    "\n",
    "Now we will extract only the subset of samples with phenotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"mkdir\", \"03_Harmonized/Phenos\"])\n",
    "idsphenos = pd.read_csv(\"../IDsRemap2016.txt\", header = None)\n",
    "for file in glob.glob(\"03_Harmonized/*harmonized.bed\"):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #First create a file with merge between phenos and fam file\n",
    "    fam  = pd.read_csv(filename + \".fam\", header = None, sep = \" \").iloc[:,[0,1]]\n",
    "    keep = pd.merge(fam.astype({1:\"str\"}), idsphenos.drop_duplicates(subset = 0), how='inner', left_on = 1, right_on = 0).iloc[:,[0,1]]\n",
    "    keepfilename = filename.split(\"/\")[0] + \"/Phenos/KEEP_\" + filename.split(\"/\")[1]\n",
    "    plinkoutfilename = filename.split(\"/\")[0] + \"/Phenos/\" + filename.split(\"/\")[1] + \"_phenos\"\n",
    "    keep.to_csv(keepfilename, header = None, index = False, sep = \" \")\n",
    "    subprocess.run([\"plink\", \"--bfile\", filename, \"--keep\", keepfilename, \"--make-bed\", \"--out\",  plinkoutfilename])\n",
    "    #count = count +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and cleaning all files\n",
    "\n",
    "Now we will merge all files into a single dataset, following the instructions stated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(os.path.join(pathgenos, \"03_Harmonized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating merging files\n",
    "#Skip this if already done\n",
    "#Remember to delete UIUC 2014 from the list\n",
    "f = open(\"30k_mergefile.txt\", \"w+\")\n",
    "for file in glob.glob(\"*harmonized.bed\"):\n",
    "    f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_2269pp_geno01_maf_hwe', '--mind', '--make-bed', '--out', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_2269pp_geno01_maf_hwe_mind01'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 500k files from Phenos folder\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"500k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01\"), \"--maf\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01_maf\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01_maf\"), \"--hwe\", \"0.001\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01_maf_hwe\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01_maf_hwe\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_2269pp_geno01_maf_hwe_mind01\")])\n",
    "\n",
    "#Founders already removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5795pp', '--geno', '--make-bed', '--out', '/home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5795pp_geno01'], returncode=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 30k files\n",
    "#There is something wrong, Euro output from harmonize step removes too many SNPs\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"30k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5795pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5795pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5795pp_geno01\")])\n",
    "\n",
    "#subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5543pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "#                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5186pp_geno01_mind01\")])\n",
    "\n",
    "#subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5186pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "#                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5069pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some intermediary files in 04_Merge folder\n",
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "removefiles = glob.glob(\"*pp.*\") + glob.glob(\"*geno01.*\") + glob.glob(\"*maf.*\") + glob.glob(\"*hwe.*\")\n",
    "for file in removefiles:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many SNPs and samples per file there are.\n",
    "There are no duplicated IIDs left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file: Merge_500k_2269pp_geno01_maf_hwe_mind01\n",
      "422161 variants loaded from .bim file.\n",
      "2269 people (851 males, 1418 females) loaded from .fam.\n",
      "0 people removed due to missing genotype data (--mind).\n",
      "422161 variants and 2269 people pass filters and QC.\n",
      "Finished file... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*.log\"):\n",
    "    with open(file) as myfile:\n",
    "        print(\"In file: \" + file.split(\".\")[0])\n",
    "        for num, line in enumerate(myfile, 1):\n",
    "            if \"people\" in line or \"variants\" in line:\n",
    "                print(line, end='')\n",
    "        print(\"Finished file... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by chromosome\n",
    "\n",
    "Now we will split the three files by chromosome to use it as input files for phasing.\n",
    "Also, for each split, we will remove genos and samples with high missing call rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*.bed\"):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #Split by chromosome\n",
    "    for i in range(1,23):\n",
    "        subprocess.run([\"plink\", \"--bfile\", filename, \"--chr\", str(i), \"--geno\", \"--mind\", \"--make-bed\", \"--out\", \"Split/\" + filename + \"_chr_\" + str(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
