{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging genotypes\n",
    "\n",
    "In this script we will take the harmonized genotypes and merge them.\n",
    "Because [fineStructure](https://people.maths.bris.ac.uk/~madjl/finestructure/) requires a lot of computational resources, we previously kept individuals with 3D face data, using the _pheno suffix. \n",
    "Note that UIUC2014 only contain duplicates from the ADAPT file, so we will remove it from further analysis.\n",
    "For each dataset (the pheno and the total) we'll split our data into two, one retaining most of our samples, and a second one only incorporating samples with denser genotype data.\n",
    "Therefore, we will have a \"dense\" (~400k) genotype file including only samples from:\n",
    "\n",
    "- ADAPT\n",
    "- SA\n",
    "- UIUC2013\n",
    "- CV\n",
    "- TD2016\n",
    "- TD2015\n",
    "- PSU_FEMMES\n",
    "\n",
    "The \"sparse\" (~20k) file will contain all of the previous datasets plus:\n",
    "\n",
    "- GHPAFF_Euro\n",
    "- Axiom Array (CHP)\n",
    "- UC_FEMMES\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Let's import modules and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths\n",
    "projpath  = os.path.realpath(\"..\")\n",
    "pathgenos = os.path.join(projpath, \"DataBases\", \"Genotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating each file by chromosome\n",
    "\n",
    "Let's first merge the different files divided by chromosomes into a single one.\n",
    "In the CV file we'll need to remove some duplicated SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering every directory in harmonize folder\n",
    "filenames = os.listdir(os.path.join(pathgenos, \"03_Harmonized\"))\n",
    "\n",
    "for filename in filenames: # loop through all the files and folders\n",
    "    if os.path.isdir(os.path.join(pathgenos, \"03_Harmonized\", filename)):\n",
    "        os.chdir(os.path.join(pathgenos, \"03_Harmonized\", filename))\n",
    "        #Opening new file and pasting the file names to use for merging\n",
    "        f = open(filename + \".txt\", \"w+\")\n",
    "        for file in glob.glob(\"*_harmonized.bed\"):\n",
    "            f.write(file.split(\".\")[0] + \"\\n\")\n",
    "        f.close()\n",
    "        if \"CV_\" in filename: #in CV we need to remove some SNPs before merging\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_excludedtemp\" )])\n",
    "            for file in glob.glob(\"*_harmonized.bed\"):\n",
    "                subprocess.run([\"plink\", \"--bfile\", file.split(\".\")[0], \"--exclude\", \n",
    "                                os.path.join(pathgenos, \"03_Harmonized\", filename + \"_excludedtemp-merge.missnp\" ), \n",
    "                                \"--make-bed\", \"--out\", file.split(\".\")[0] + \"_temp\"])\n",
    "                \n",
    "            f = open(filename + \".txt\", \"w+\")\n",
    "            for file in glob.glob(\"*_temp.bed\"):\n",
    "                f.write(file.split(\".\")[0] + \"\\n\")\n",
    "            f.close()\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "            for file in glob.glob(\"*_temp.*\"):\n",
    "                os.remove(file)   \n",
    "                \n",
    "        else:\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and cleaning all files\n",
    "\n",
    "Now we will merge the harmonized files into four different dataset as explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(os.path.join(pathgenos, \"03_Harmonized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating initial merging files without UIUC2014\n",
    "f = open(\"merge_dense_phenos.txt\", \"w+\")\n",
    "exclude = [\"UIUC2014\", \"Euro\", \"CHP\", \"UC_FEMMES\"]\n",
    "for file in glob.glob(\"*phenos*harmonized.bed\"):\n",
    "    if any(x in file for x in exclude):\n",
    "        pass\n",
    "    else:\n",
    "        f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"merge_dense_all.txt\", \"w+\")\n",
    "exclude = [\"phenos\", \"UIUC2014\", \"Euro\", \"CHP\", \"UC_FEMMES\"]\n",
    "for file in glob.glob(\"*harmonized.bed\"):\n",
    "    if any(x in file for x in exclude):\n",
    "        pass\n",
    "    else:\n",
    "        f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(\"merge_sparse_phenos.txt\", \"w+\")\n",
    "for file in glob.glob(\"*phenos*harmonized.bed\"):\n",
    "    if \"UIUC2014\" in file:\n",
    "        pass\n",
    "    else:\n",
    "        f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"merge_sparse_all.txt\", \"w+\")\n",
    "for file in glob.glob(\"*harmonized.bed\"):\n",
    "    if \"phenos\" in file:\n",
    "        pass\n",
    "    else:\n",
    "        if \"UIUC2014\" in file:\n",
    "            pass\n",
    "        else:\n",
    "            f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all listed files, create SNP list to exclude and exclude them from all files to merge\n",
    "\n",
    "for setfile in glob.glob(\"merge*.txt\"): #For each file with the list of datasets create a file of excluded SNPs\n",
    "    setname   = setfile.split(\".\")[0]\n",
    "    filenames = pd.read_csv(setfile, header = None) #reading file to get the database names\n",
    "    subprocess.run([\"plink\", \"--merge-list\", setfile, \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, \"ExcludeSnps\") ])\n",
    "    for i in range(1, (len(filenames.index)) ): #excluding SNPs from each database on the list\n",
    "        subprocess.run([\"plink\", \"--bfile\", filenames.iloc[i,0], \"--exclude\", os.path.join(pathgenos, \"04_Merge\", setname, \"ExcludeSnps-merge.missnp\"),\n",
    "                        \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, filenames.iloc[i,0] + \"_excludedtemp\") ])\n",
    "    f = open(os.path.join(pathgenos, \"04_Merge\", setname, \"mergefile.txt\"), \"w+\") #creating a new mergefile with the databases with excluded SNPs\n",
    "    for bedfile in glob.glob(os.path.join(pathgenos, \"04_Merge\", setname, \"*.bed\") ):\n",
    "        f.write(bedfile.split(\".\")[0] + \"\\n\")\n",
    "    f.close()\n",
    "    #Second merging for all phenos file and QC process\n",
    "    subprocess.run([\"plink\", \"--merge-list\", os.path.join(pathgenos, \"04_Merge\", setname, \"mergefile.txt\"), \n",
    "                    \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, setname) ])\n",
    "\n",
    "    subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", setname, setname), \n",
    "                    \"--geno\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\") ])\n",
    "\n",
    "    subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\"), \n",
    "                    \"--maf\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\" + \"_maf\")])\n",
    "\n",
    "    subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\" + \"_maf\"), \n",
    "                    \"--hwe\", \"0.001\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\" + \"_maf\" + \"_hwe\") ])\n",
    "\n",
    "    subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\" + \"_maf\" + \"_hwe\"), \n",
    "                    \"--mind\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", setname, setname + \"_geno\" + \"_maf\" + \"_hwe\" + \"_mind01\")])\n",
    "    \n",
    "    for file in glob.glob(os.path.join(pathgenos, \"04_Merge\", setname, \"*\") ): #Removing intermediary files\n",
    "        exclude = [\"mind01.\", \"split\"]\n",
    "        if any(x in file for x in exclude):\n",
    "            pass\n",
    "        else:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many SNPs and samples per file there are.\n",
    "There are no duplicated IIDs left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file: /home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/merge_dense_all/merge_dense_all_geno_maf_hwe_mind01\n",
      "201736 variants loaded from .bim file.\n",
      "3533 people (1312 males, 2221 females) loaded from .fam.\n",
      "90 people removed due to missing genotype data (--mind).\n",
      "201736 variants and 3443 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: /home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/merge_sparse_all/merge_sparse_all_geno_maf_hwe_mind01\n",
      "18114 variants loaded from .bim file.\n",
      "4194 people (1463 males, 2502 females, 229 ambiguous) loaded from .fam.\n",
      "319 people removed due to missing genotype data (--mind).\n",
      "18114 variants and 3875 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: /home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/merge_sparse_phenos/merge_sparse_phenos_geno_maf_hwe_mind01\n",
      "21400 variants loaded from .bim file.\n",
      "3692 people (1163 males, 2310 females, 219 ambiguous) loaded from .fam.\n",
      "309 people removed due to missing genotype data (--mind).\n",
      "21400 variants and 3383 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: /home/tomas/Documents/Research/PopStruct/DataBases/Genotypes/04_Merge/merge_dense_phenos/merge_dense_phenos_geno_maf_hwe_mind01\n",
      "369527 variants loaded from .bim file.\n",
      "3057 people (1018 males, 2039 females) loaded from .fam.\n",
      "90 people removed due to missing genotype data (--mind).\n",
      "369527 variants and 2967 people pass filters and QC.\n",
      "Finished file... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(os.path.join(pathgenos, \"04_Merge\", \"**\", \"*.log\") ):\n",
    "    with open(file) as myfile:\n",
    "        print(\"In file: \" + file.split(\".\")[0])\n",
    "        for num, line in enumerate(myfile, 1):\n",
    "            if \"people\" in line or \"variants\" in line:\n",
    "                print(line, end='')\n",
    "        print(\"Finished file... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by chromosome\n",
    "\n",
    "Now we will split the merged files by chromosome to use it as input for phasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(os.path.join(\"**\", \"*.bed\") ):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #Split by chromosome\n",
    "    for i in range(1,23):\n",
    "        subprocess.run([\"plink\", \"--bfile\", filename, \"--chr\", str(i), \"--make-bed\", \"--out\", \n",
    "        filename.split(\"/\")[0] + \"/split/\" + filename.split(\"/\")[1] + \"_chr_\" + str(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
