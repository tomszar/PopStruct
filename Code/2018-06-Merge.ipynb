{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging genotypes\n",
    "\n",
    "In this script we will take the harmonized genotypes and merge them.\n",
    "We will have as output three different files, a \"dense\" file with samples with ~500k SNPs, a \"medium\" one with samples with ~300k, and a \"sparse\" one with all the files (~100k).\n",
    "The list of files is as follows:\n",
    "\n",
    "- Dense:\n",
    "    - UIUC2013\n",
    "    - UIUC2014\n",
    "    - TD2015\n",
    "    - TD2016\n",
    "    - SA\n",
    "    - ADAPT\n",
    "    - PSU_FEMMES\n",
    "\n",
    "- Medium:\n",
    "    - All of the above\n",
    "    - GHPAFF_Euro\n",
    "    - GHPAFF_CV\n",
    "\n",
    "- Sparse:\n",
    "    - All of the above\n",
    "    - Axiom Array\n",
    "    - UC_FEMMES (Note that adding UC_FEMMES, the number of SNPs decreases from ~30k to ~10k)\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Let's import modules and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths\n",
    "projpath  = os.path.realpath(\"..\")\n",
    "pathgenos = os.path.join(projpath, \"DataBases\", \"Genotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging each file\n",
    "\n",
    "Let's first merge the different files divided by chromosomes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(pathgenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering every directory in harmonize folder\n",
    "filenames = os.listdir(os.path.join(pathgenos, \"03_Harmonized\"))\n",
    "\n",
    "for filename in filenames: # loop through all the files and folders\n",
    "    if os.path.isdir(os.path.join(pathgenos, \"03_Harmonized\", filename)):\n",
    "        os.chdir(os.path.join(pathgenos, \"03_Harmonized\", filename))\n",
    "        #Opening new file and pasting the file names to use for merging\n",
    "        f = open(filename + \".txt\", \"w+\")\n",
    "        for file in glob.glob(\"*_harmonized.bed\"):\n",
    "            f.write(file.split(\".\")[0] + \"\\n\")\n",
    "        f.close()\n",
    "        #Merge using the file just created. Remove no-sex in CHP (those are plate controls)\n",
    "        if filename.startswith(\"CHP\"):\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "            subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\"), \n",
    "                            \"--remove\", os.path.join(pathgenos, \"03_Harmonized\", \"CHP_1022ppl_114K_hg19_ATGC_geno01_mind01_all_harmonized.nosex\"), \n",
    "                            \"--make-bed\", \"--out\", os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])\n",
    "        else:\n",
    "            subprocess.run([\"plink\", \"--merge-list\", filename + \".txt\", \"--allow-no-sex\", \"--make-bed\", \"--out\", \n",
    "                            os.path.join(pathgenos, \"03_Harmonized\", filename + \"_all_harmonized\" )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and cleaning all files\n",
    "\n",
    "Now we will merge all files into a single dataset, following the instructions stated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move directory\n",
    "os.chdir(os.path.join(pathgenos, \"03_Harmonized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating merging files\n",
    "f = open(\"30k_mergefile.txt\", \"w+\")\n",
    "for file in glob.glob(\"*harmonized.bed\"):\n",
    "    f.write(file.split(\".\")[0] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_3729pp_geno01_mind01', '--filter-founders', '--make-bed', '--out', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_500k_3612pp_geno01_mind01_founders'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 500k files\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"500k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3910pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3910pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3910pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3910pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3729pp_geno01_mind01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3729pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_500k_3612pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_300k_4426pp_geno01_mind01', '--filter-founders', '--make-bed', '--out', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_300k_4309pp_geno01_mind01_founders'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 300k files\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"300k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4783pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4783pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4783pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4783pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4426pp_geno01_mind01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4426pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_300k_4309pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink', '--bfile', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5345pp_geno01_mind01', '--filter-founders', '--make-bed', '--out', '/home/tomas/Documents/PopStruct/DataBases/Genotypes/04_Merge/Merge_30k_5228pp_geno01_mind01_founders'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging 30k files\n",
    "subprocess.run([\"plink\", \"--merge-list\", \"30k_mergefile.txt\", \"--make-bed\", \"--out\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5702pp\") ])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5702pp\"), \"--geno\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5702pp_geno01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5702pp_geno01\"), \"--mind\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5345pp_geno01_mind01\")])\n",
    "\n",
    "subprocess.run([\"plink\", \"--bfile\", os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5345pp_geno01_mind01\"), \"--filter-founders\", \"--make-bed\", \"--out\", \n",
    "                os.path.join(pathgenos, \"04_Merge\", \"Merge_30k_5228pp_geno01_mind01_founders\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some intermediary files in 04_Merge folder\n",
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*pp.*\"):\n",
    "    os.remove(file)\n",
    "for file in glob.glob(\"*geno01.*\"):\n",
    "    os.remove(file)\n",
    "for file in glob.glob(\"*mind01.*\"):\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many SNPs and samples per file there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file: Merge_300k_4309pp_geno01_mind01_founders\n",
      "290001 variants loaded from .bim file.\n",
      "4426 people (1251 males, 2478 females, 697 ambiguous) loaded from .fam.\n",
      "117 people removed due to founder status (--filter-founders).\n",
      "290001 variants and 4309 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: Merge_500k_3612pp_geno01_mind01_founders\n",
      "497305 variants loaded from .bim file.\n",
      "3729 people (1251 males, 2478 females) loaded from .fam.\n",
      "117 people removed due to founder status (--filter-founders).\n",
      "497305 variants and 3612 people pass filters and QC.\n",
      "Finished file... \n",
      "\n",
      "In file: Merge_30k_5228pp_geno01_mind01_founders\n",
      "29597 variants loaded from .bim file.\n",
      "5345 people (1583 males, 3065 females, 697 ambiguous) loaded from .fam.\n",
      "117 people removed due to founder status (--filter-founders).\n",
      "29597 variants and 5228 people pass filters and QC.\n",
      "Finished file... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*.log\"):\n",
    "    with open(file) as myfile:\n",
    "        print(\"In file: \" + file.split(\".\")[0])\n",
    "        for num, line in enumerate(myfile, 1):\n",
    "            if \"people\" in line or \"variants\" in line:\n",
    "                print(line, end='')\n",
    "        print(\"Finished file... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing repeated IIDs\n",
    "\n",
    "There are some repeated IIDs but with different FID (are those the same?).\n",
    "But at this point we will remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*.fam\"):\n",
    "    fam    = pd.read_csv(file, sep = \" \", header = None).drop_duplicates(subset = 1)\n",
    "    fam.iloc[:,0:2].to_csv(file.split(\".\")[0] + \"_keep.fam\", sep = \" \", header = False, index = False)\n",
    "    subprocess.run([\"plink\", \"--bfile\", file.split(\".\")[0], \"--keep\", file.split(\".\")[0] + \"_keep.fam\", \n",
    "                    \"--make-bed\", \"--out\", file.split(\".\")[0] + \"_unique\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by chromosome\n",
    "\n",
    "Now we will split the three files by chromosome to use it as input files for phasing.\n",
    "Also, for each split, we will remove genos and samples with high missing call rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(pathgenos, \"04_Merge\"))\n",
    "for file in glob.glob(\"*_unique.bed\"):\n",
    "    filename = file.split(\".\")[0]\n",
    "    #Split by chromosome\n",
    "    for i in range(1,23):\n",
    "        subprocess.run([\"plink\", \"--bfile\", filename, \"--chr\", str(i), \"--geno\", \"--mind\", \"--make-bed\", \"--out\", \"Split/\" + filename + \"_chr_\" + str(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
